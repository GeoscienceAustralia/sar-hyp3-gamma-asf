{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Using the HyP3 SDK for Python\n",
    "https://nbviewer.org/github/ASFHyP3/hyp3-sdk/blob/main/docs/sdk_example.ipynb#Submitting-Sentinel-1-InSAR-jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asf_search as asf\n",
    "import hyp3_sdk as sdk\n",
    "from hyp3_sdk import HyP3\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy\n",
    "import geopandas as gpd\n",
    "import pyproj\n",
    "import antimeridian\n",
    "import os\n",
    "import zipfile\n",
    "import rasterio\n",
    "from utils import upload_file\n",
    "import json\n",
    "import ntpath \n",
    "import shutil\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygon_from_bounds(xmin, xmax, ymin, ymax):\n",
    "    point1 = (float(xmin), float(ymax))\n",
    "    point2 = (float(xmax), float(ymax))\n",
    "    point3 = (float(xmax), float(ymin))\n",
    "    point4 = (float(xmin), float(ymin))\n",
    "    # Create a Shapely polygon from the points\n",
    "    aoi = Polygon([point1, point2, point3, point4])\n",
    "    return aoi\n",
    "\n",
    "def transform_polygon(src_crs, dst_crs, geometry, always_xy=True):\n",
    "    src_crs = pyproj.CRS(f\"EPSG:{src_crs}\")\n",
    "    dst_crs = pyproj.CRS(f\"EPSG:{dst_crs}\") \n",
    "    transformer = pyproj.Transformer.from_crs(src_crs, dst_crs, always_xy=always_xy)\n",
    "     # Transform the polygon's coordinates\n",
    "    transformed_exterior = [\n",
    "        transformer.transform(x, y) for x, y in geometry.exterior.coords\n",
    "    ]\n",
    "    # Create a new Shapely polygon with the transformed coordinates\n",
    "    transformed_polygon = Polygon(transformed_exterior)\n",
    "    return transformed_polygon\n",
    "\n",
    "def plot_polygons(polygons, bounds, crs=4326, colour='dodgerblue', colours=[]):\n",
    "    plt.rcParams[\"figure.figsize\"] = [10,8]\n",
    "    # plot the the product geometries on a map\n",
    "    east, west, south, north = bounds\n",
    "    #ax = plt.axes(projection=cartopy.crs.PlateCarree())\n",
    "    ax = plt.axes(projection=cartopy.crs.SouthPolarStereo())\n",
    "    ax.set_extent((east, west, south, north), cartopy.crs.PlateCarree())\n",
    "    ax.add_feature(cartopy.feature.LAND)\n",
    "    ax.add_feature(cartopy.feature.OCEAN)\n",
    "    #proj = cartopy.crs.SouthPolarStereo() if crs==3031 else cartopy.crs.PlateCarree()\n",
    "    for i,polygon in enumerate(polygons):\n",
    "        c = colours[i] if colours else colour\n",
    "        ax.add_geometries(polygon, \n",
    "                        crs=cartopy.crs.PlateCarree(), \n",
    "                        alpha=0.3, \n",
    "                        edgecolor='black',\n",
    "                        facecolor=c,\n",
    "                        linewidth=1\n",
    "                        #fillcolor='white'\n",
    "                        ) \n",
    "    ax.gridlines(draw_labels=True)\n",
    "    ax.add_feature(cartopy.feature.COASTLINE)\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticating to the API\n",
    "\n",
    "The SDK will attempt to pull your [NASA Earthdata Login](https://urs.earthdata.nasa.gov/) credentials out of `~/.netrc`\n",
    "by default, or you can pass your credentials in directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"credentials/credentials_earthdata.yaml\", \"r\", encoding='utf8') as f:\n",
    "   earthdata_cfg = yaml.safe_load(f.read())\n",
    "   uid = earthdata_cfg['login']\n",
    "   pswd = earthdata_cfg['password']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp3 = HyP3(username=uid, password=pswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_list = True\n",
    "if search_list:\n",
    "    iw_scene_list = [\n",
    "        # Antarctica - Maitri Station (-70.76683, 11.7308)\n",
    "        'S1B_IW_SLC__1SSH_20190315T195015_20190315T195045_015369_01CC73_DB8B',\n",
    "        'S1B_IW_SLC__1SSH_20190327T195016_20190327T195045_015544_01D236_9504',\n",
    "        'S1B_IW_SLC__1SSH_20190526T195018_20190526T195048_016419_01EE8D_53BC',\n",
    "        # Antarctica - Bharati Station (-69.4068, 76.19525)\n",
    "        'S1B_IW_SLC__1SSH_20190223T222639_20190223T222706_015079_01C2E9_1D63',\n",
    "        'S1A_IW_SLC__1SSH_20190605T222724_20190605T222751_027550_031BE1_AD3A',\n",
    "        # Antarctica - lutzow-holm bay (-69.6901, 39.4502)\n",
    "        'S1A_IW_SLC__1SSH_20220223T175626_20220223T175653_042043_05021A_BB8E',\n",
    "        'S1A_IW_SLC__1SSH_20221021T175636_20221021T175703_045543_0571D7_989F',\n",
    "        # Antarctica - Erebus Ice Tongue (-77.7018, 166.7541) \n",
    "        'S1A_IW_SLC__1SSH_20190926T124734_20190926T124804_029192_0350B9_FA6B',\n",
    "        # Antarctica - Heard, McDonald Island (-53.1057, 73.5431) \n",
    "        'S1A_IW_SLC__1SSH_20230127T142750_20230127T142817_046970_05A22F_17F7',\n",
    "        'S1A_IW_SLC__1SSH_20230620T142747_20230620T142817_049070_05E69E_0BC7',\n",
    "        # Antarctica - Brunt Ice Shelf (-75.216667, -25.683333) \n",
    "        'S1B_IW_SLC__1SSH_20210223T233056_20210223T233124_025740_031194_E7BE',\n",
    "        'S1B_IW_SLC__1SSH_20210228T035005_20210228T035033_025801_03138F_8CB2',\n",
    "        # Antarctica - Victoria Land, East Ross Sea (-72.5, 168) \n",
    "        'S1A_IW_SLC__1SSH_20230120T160153_20230120T160220_046869_059EC6_F364',\n",
    "        'S1A_IW_SLC__1SSH_20230116T100627_20230116T100655_046807_059CB3_FCC7',\n",
    "   ]\n",
    "\n",
    "    ew_scene_list = [\n",
    "        'S1A_EW_GRDM_1SDH_20220225T174025_20220225T174129_042072_050315_7C35',\n",
    "        'S1A_EW_GRDM_1SDH_20221023T174035_20221023T174139_045572_0572D2_CD12',\n",
    "        'S1A_EW_GRDM_1SDH_20190924T112554_20190924T112659_029162_034FAB_41A7',\n",
    "        'S1A_EW_GRDM_1SDH_20230118T112609_20230118T112713_046837_059DB3_9C85',\n",
    "        'S1B_EW_GRDM_1SDH_20210221T234712_20210221T234816_025711_0310AD_3C16',\n",
    "        'S1B_EW_GRDM_1SDH_20210304T000326_20210304T000430_025857_031578_789C',\n",
    "    ]\n",
    "\n",
    "    sm_scene_list = [\n",
    "        'S1A_S3_SLC__1SSH_20230925T000119_20230925T000138_050476_06143F_154F',\n",
    "        'S1A_S3_SLC__1SSH_20200108T000054_20200108T000113_030701_0384ED_8266'\n",
    "    ]\n",
    "\n",
    "    qld_CR_list = [\n",
    "        # Australia - QLD corner reflector (-27.0252,150.5759)\n",
    "        'S1A_IW_SLC__1SSH_20220104T083315_20220104T083342_041308_04E91B_8E5F',\n",
    "        'S1A_IW_SLC__1SDV_20220111T192213_20220111T192240_041417_04ECBD_9F3B',\n",
    "        'S1A_IW_SLC__1SSH_20220116T083314_20220116T083342_041483_04EED2_DB08',\n",
    "        'S1A_IW_SLC__1SDV_20220123T192213_20220123T192240_041592_04F283_9D0E',\n",
    "    ]\n",
    "\n",
    "\n",
    "    # search the scene list with the specified product type\n",
    "    iw_results = asf.granule_search(iw_scene_list, asf.ASFSearchOptions(processingLevel='SLC'))\n",
    "    ew_results = asf.granule_search(ew_scene_list, asf.ASFSearchOptions(processingLevel='GRD_MD'))\n",
    "    sm_results = asf.granule_search(sm_scene_list, asf.ASFSearchOptions(processingLevel='SLC'))\n",
    "    qld_cr_results = asf.granule_search(qld_CR_list, asf.ASFSearchOptions(processingLevel='SLC'))\n",
    "    \n",
    "results = iw_results + ew_results + sm_results\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_locations = {}\n",
    "scene_locations_3031 = {}\n",
    "for r in results:\n",
    "    id = r.__dict__['umm']['GranuleUR'].split('-')[0]\n",
    "    # print(r.__dict__['umm']['GranuleUR'].split('-')[0])\n",
    "    # print(r.__dict__['umm']['AdditionalAttributes'][1]['Values'],\n",
    "    #       r.__dict__['umm']['AdditionalAttributes'][17],\n",
    "    #       r.__dict__['umm']['OrbitCalculatedSpatialDomains'][0]) #[1] #['FRAME_NUMBER']\n",
    "    # print(r.__dict__['umm']['SpatialExtent'])\n",
    "    points = (r.__dict__['umm']['SpatialExtent']['HorizontalSpatialDomain']\n",
    "              ['Geometry']['GPolygons'][0]['Boundary']['Points'])\n",
    "    points = [(p['Longitude'],p['Latitude']) for p in points]\n",
    "    poly = Polygon(points)\n",
    "    poly_3031 = transform_polygon(4326, 3031, poly, always_xy=True)\n",
    "    poly = antimeridian.fix_polygon(poly)\n",
    "    scene_locations[id] = poly\n",
    "    scene_locations_3031[id] = poly_3031\n",
    "\n",
    "# save locations to file\n",
    "# df = pd.DataFrame.from_dict(scene_locations_3031, orient='index')\n",
    "# df = df.rename(columns = {0:'geometry'})\n",
    "# gdf = gpd.GeoDataFrame(df, crs=3031, geometry='geometry')\n",
    "# gdf.to_file('antarctic_test_scene_locations.json')\n",
    "\n",
    "#plot\n",
    "colours = ['green' if 'IW' in x else ('blue' if 'EW' in x else 'red') for x in scene_locations.keys()]\n",
    "plot_polygons(scene_locations.values(), (-180,180,-90,-53), colours=colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download = False\n",
    "download_folder = 'data'\n",
    "if download:\n",
    "    session = asf.ASFSession()\n",
    "    session.auth_with_creds(uid,pswd)\n",
    "    # download all results\n",
    "    scene_paths = []\n",
    "    for scene in results:\n",
    "        name = scene.__dict__['umm']['GranuleUR'].split('-')[0]\n",
    "        print(name)\n",
    "        path = os.path.join(download_folder, name)\n",
    "        scene.download(path=download_folder, session=session)\n",
    "        scene_paths.append(path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting jobs\n",
    "\n",
    "The SDK provides a submit method for [all supported job types](https://hyp3-docs.asf.alaska.edu/products/).\n",
    "\n",
    "### Submitting Sentinel-1 RTC jobs\n",
    "\n",
    "Sentinel-1 Radiometric Terrain Correction (RTC) jobs are submitted using [ESA granule IDs](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/naming-conventions).\n",
    "The example granules below can be viewed  in [ASF Search here](https://search.asf.alaska.edu/#/?zoom=7.08772014623877&center=-141.733866,58.498008&resultsLoaded=true&granule=S1A_IW_SLC__1SDV_20210214T154835_20210214T154901_036588_044C54_8494-SLC&searchType=List%20Search&searchList=S1A_IW_SLC__1SDV_20210214T154835_20210214T154901_036588_044C54_8494-SLC,S1B_IW_SLC__1SDV_20210210T153131_20210210T153159_025546_030B48_B568-SLC,S1A_IW_SLC__1SDV_20210210T025526_20210210T025553_036522_0449E2_7769-SLC,S1A_IW_SLC__1SDV_20210210T025501_20210210T025528_036522_0449E2_3917-SLC,S1B_IW_SLC__1SDV_20210209T030255_20210209T030323_025524_030A8D_7E88-SLC,S1B_IW_SLC__1SDV_20210209T030227_20210209T030257_025524_030A8D_5BAF-SLC,S1A_IW_SLC__1SDV_20210202T154835_20210202T154902_036413_044634_01A1-SLC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = {\n",
    "    'antarctica-comparison-iw': iw_scene_list,\n",
    "    'antarctica-comparison-ew': ew_scene_list,\n",
    "    'antarctica-comparison-sm': sm_scene_list,\n",
    "    'qld-cr-2022-01': qld_CR_list,\n",
    "}\n",
    "# set the proj name\n",
    "proj_name = 'antarctica-comparison-iw'\n",
    "proj_name = 'qld-cr-2022-01'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit jobs\n",
    "rtc_jobs = sdk.Batch()\n",
    "scene_list = projects[proj_name]\n",
    "for g in scene_list:\n",
    "    rtc_jobs += hyp3.submit_rtc_job(g, \n",
    "                                    include_dem=True, #include dem in final product\n",
    "                                    include_inc_map=True,  #include dem map in final product\n",
    "                                    include_rgb=True,  #include rgb img in final product\n",
    "                                    include_scattering_area=True, #include scat area in final product\n",
    "                                    name=proj_name,\n",
    "                                    resolution=20,\n",
    "                                    dem_name='copernicus')\n",
    "print(rtc_jobs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we've given each job the name `rtc-example`, which we can use later to search for these jobs.\n",
    "\n",
    "`HyP3.submit_rtc_job` also accepts\n",
    "[keyword arguments](https://hyp3-docs.asf.alaska.edu/using/sdk_api/#hyp3_sdk.hyp3.HyP3.submit_rtc_job)\n",
    "to customize the RTC products to your application."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watch Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtc_jobs = hyp3.find_jobs(name=proj_name)\n",
    "rtc_jobs = hyp3.watch(rtc_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtc_jobs = hyp3.find_jobs(name=proj_name)\n",
    "rtc_jobs = hyp3.refresh(rtc_jobs)\n",
    "running_jobs = rtc_jobs.filter_jobs(succeeded=False, running=True, failed=False)\n",
    "print(f'Number of running jobs: {len(running_jobs)}')\n",
    "succeeded_jobs = rtc_jobs.filter_jobs(succeeded=True, running=False, failed=False)\n",
    "print(f'Number of succeeded jobs: {len(succeeded_jobs)}')\n",
    "failed_jobs = rtc_jobs.filter_jobs(succeeded=False, running=False, failed=True)\n",
    "print(f'Number of failed jobs: {len(failed_jobs)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download, Unzip and Push to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_folder = '/data/hyp3-gamma'\n",
    "s3_bucket = 'deant-data-public-dev'\n",
    "push_to_s3 = True\n",
    "delete_after_upload = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set credentials for pushing to s3 bucket\n",
    "with open('credentials/credentials_aws.yaml', \"r\", encoding='utf8') as f:\n",
    "    aws_cfg = yaml.safe_load(f.read())\n",
    "    # set all keys as environment variables\n",
    "    for k in aws_cfg.keys():\n",
    "        os.environ[k] = aws_cfg[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timing_dict():\n",
    "    # timing file with same structure as used for rtc-opera and\n",
    "    # pyrosar. Fill with zeros.\n",
    "    return {\n",
    "        \"Download Scene\":\t0,\n",
    "        \"Download Orbits\":\t0,\n",
    "        \"Download DEM\":\t0,\n",
    "        \"RTC Processing\":\t0,\n",
    "        \"S3 Upload\":\t0,\n",
    "        \"Delete Files\":\t0,\n",
    "        \"Total\":\t0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in succeeded_jobs:\n",
    "    # download\n",
    "    file_list = job.download_files(download_folder)\n",
    "    process_time = job.processing_times\n",
    "    _, filename = ntpath.split(str(file_list[0]))\n",
    "    st = filename.split('_')[2]\n",
    "    scene = [x for x in projects[proj_name] if st in x][0]\n",
    "    print(scene)\n",
    "    # unzip\n",
    "    with zipfile.ZipFile(file_list[0], 'r') as zip_ref:\n",
    "        zip_ref.extractall(download_folder)\n",
    "    os.remove(file_list[0])\n",
    "    prod_folder = os.path.join(download_folder, str(file_list[0]).replace('.zip',''))\n",
    "    tif_file = [x for x in os.listdir(prod_folder) \n",
    "                    if (x.endswith('.tif') and any(ph in x for ph in ['HH','HV','VV','VH']))][0]\n",
    "    # get the crs from the tif\n",
    "    with rasterio.open(str(os.path.join(prod_folder, tif_file))) as src:\n",
    "        crs = src.meta['crs']\n",
    "        crs = str(crs).split(':')[-1]\n",
    "    #make the timing file\n",
    "    timing_dict = make_timing_dict()\n",
    "    timing_dict['Total'] = process_time\n",
    "    timing_dict['RTC Processing'] = process_time\n",
    "    timing_path = os.path.join(prod_folder,f'{scene}_timing.json')\n",
    "    with open(timing_path, 'w') as fp:\n",
    "        json.dump(timing_dict, fp)\n",
    "    for f in os.listdir(prod_folder):\n",
    "        f_path = os.path.join(prod_folder, f)\n",
    "        if push_to_s3:\n",
    "            bucket_folder = f\"hyp3-gamma/glo_30/{crs}/{scene}\"\n",
    "            object_name = f\"{bucket_folder}/{f}\"\n",
    "            upload_file(f_path,s3_bucket,object_name)\n",
    "    if delete_after_upload:\n",
    "        shutil.rmtree(prod_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Submitting Sentinel-1 InSAR jobs\n",
    "\n",
    "The SDK can also submit Sentinel-1 Interferometric Synthetic Aperture Radar (InSAR) jobs which processes\n",
    "reference and secondary granule pairs.\n",
    "\n",
    "For a particular reference granule, we may want to use the nearest and next-nearest temporal neighbor granules as secondary\n",
    "scenes. To programmatically find our secondary granules for a reference granule, We'll define a `get_nearest_neighbors`\n",
    "function that uses the [baseline stack](https://docs.asf.alaska.edu/asf_search/ASFProduct/#stack) method from `asf_search`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "def get_nearest_neighbors(granule: str, max_neighbors: Optional[int] = None) -> asf.ASFSearchResults:\n",
    "    #granule = asf.granule_search(granule)[-1] #original code commented out because didnt work...\n",
    "    granule = asf.granule_search(granule)[0]\n",
    "    stack = reversed([item for item in granule.stack() if item.properties['temporalBaseline'] < 0])\n",
    "    results = asf.ASFSearchResults(stack)[:max_neighbors]\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, using the example granule list for our RTC jobs as the reference scenes, we can find their nearest and next-nearest neighbor granules, and submit them\n",
    "as pairs for InSAR processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm  # For a nice progress bar: https://github.com/tqdm/tqdm#ipython-jupyter-integration\n",
    "\n",
    "granules = [\n",
    "    'S1A_IW_SLC__1SDV_20210214T154835_20210214T154901_036588_044C54_8494',\n",
    "    'S1B_IW_SLC__1SDV_20210210T153131_20210210T153159_025546_030B48_B568',\n",
    "    'S1A_IW_SLC__1SDV_20210210T025526_20210210T025553_036522_0449E2_7769',\n",
    "    'S1A_IW_SLC__1SDV_20210210T025501_20210210T025528_036522_0449E2_3917',\n",
    "    'S1B_IW_SLC__1SDV_20210209T030255_20210209T030323_025524_030A8D_7E88',\n",
    "    'S1B_IW_SLC__1SDV_20210209T030227_20210209T030257_025524_030A8D_5BAF',\n",
    "    'S1A_IW_SLC__1SDV_20210202T154835_20210202T154902_036413_044634_01A1',\n",
    "]\n",
    "\n",
    "insar_jobs = sdk.Batch()\n",
    "for reference in tqdm(granules):\n",
    "    neighbors = get_nearest_neighbors(reference, max_neighbors=2)\n",
    "    for secondary in neighbors:\n",
    "        print(f'Reference: {reference}')\n",
    "        print(f'Secondary: {secondary.properties[\"sceneName\"]}')\n",
    "        insar_jobs += hyp3.submit_insar_job(\n",
    "            reference, \n",
    "            secondary.properties['sceneName'], \n",
    "            name='insar-example-extra',\n",
    "            include_look_vectors = True,\n",
    "            include_los_displacement = True,\n",
    "            include_inc_map = True,\n",
    "            looks = '20x4', #'20x4', '10x2'\n",
    "            include_dem = True,\n",
    "            include_wrapped_phase = True,\n",
    "            apply_water_mask = True,\n",
    "            include_displacement_maps = True\n",
    "            )\n",
    "print(insar_jobs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watch Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insar_jobs = hyp3.find_jobs(name='insar-example-extra')\n",
    "insar_jobs = hyp3.watch(insar_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insar_jobs = hyp3.refresh(insar_jobs)\n",
    "succeeded_jobs = insar_jobs.filter_jobs(succeeded=True, running=False, failed=False)\n",
    "print(f'Number of succeeded jobs: {len(succeeded_jobs)}')\n",
    "failed_jobs = insar_jobs.filter_jobs(succeeded=False, running=False, failed=True)\n",
    "print(f'Number of failed jobs: {len(failed_jobs)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = succeeded_jobs.download_files()\n",
    "file_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check status"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Like RTC jobs, `HyP3.submit_insar_job` accepts\n",
    "[keyword arguments](https://hyp3-docs.asf.alaska.edu/using/sdk_api/#hyp3_sdk.hyp3.HyP3.submit_insar_job)\n",
    "to customize the InSAR products to your application."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting autoRIFT jobs\n",
    "\n",
    "AutoRIFT supports processing Sentinel-1, Sentinel-2, or Landsat-8 Collection 2 pairs.\n",
    "* Sentinel-1 jobs are submitted using [ESA granule IDs](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/naming-conventions)\n",
    "* Sentinel-2 jobs are submitted using [ESA granule IDs](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/naming-convention)\n",
    "* Landsat-8 Collection 2 jobs are submitted using [USGS scene IDs](https://www.usgs.gov/faqs/what-naming-convention-landsat-collection-2-level-1-and-level-2-scenes?qt-news_science_products=0#qt-news_science_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autorift_pairs = [\n",
    "    # Sentinel-1 ESA granule IDs\n",
    "    ('S1A_IW_SLC__1SSH_20170221T204710_20170221T204737_015387_0193F6_AB07',\n",
    "     'S1B_IW_SLC__1SSH_20170227T204628_20170227T204655_004491_007D11_6654'),\n",
    "    # Sentinel-2 ESA granule IDs\n",
    "    ('S2B_MSIL1C_20200612T150759_N0209_R025_T22WEB_20200612T184700',\n",
    "     'S2A_MSIL1C_20200627T150921_N0209_R025_T22WEB_20200627T170912'),\n",
    "    # Landsat 8\n",
    "    ('LC08_L1TP_009011_20200703_20200913_02_T1',\n",
    "     'LC08_L1TP_009011_20200820_20200905_02_T1'),\n",
    "]\n",
    "\n",
    "autorift_jobs = sdk.Batch()\n",
    "for reference, secondary in autorift_pairs:\n",
    "    autorift_jobs += hyp3.submit_autorift_job(reference, secondary, name='autorift-example')\n",
    "print(autorift_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autorift_jobs = hyp3.watch(autorift_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autorift_jobs = hyp3.refresh(autorift_jobs)\n",
    "succeeded_jobs = autorift_jobs.filter_jobs(succeeded=True, running=False, failed=False)\n",
    "print(f'Number of succeeded jobs: {len(succeeded_jobs)}')\n",
    "failed_jobs = autorift_jobs.filter_jobs(succeeded=False, running=False, failed=True)\n",
    "print(f'Number of failed jobs: {len(failed_jobs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = succeeded_jobs.download_files()\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
